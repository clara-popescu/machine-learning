{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c144720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import HTTPError, RequestException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3f478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex + cleaning helpers\n",
    "\n",
    "unit_re = re.compile(\n",
    "    r\"\\b(\\d+(\\.\\d+)?\\s?(g|kg|ml|l|cl|oz|lb|pack|pcs|pc|x))\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "multispace_re = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "def clean_name(s: str) -> str:\n",
    "    # normalise product names so they look like shopping-list items.\n",
    "    s = (s or \"\").strip().lower()\n",
    "    s = s.replace(\"_\", \" \")\n",
    "    s = unit_re.sub(\"\", s)\n",
    "    # remove most punctuation but keep &, ' and -\n",
    "    s = re.sub(r\"[^\\w\\s&'-]\", \" \", s)\n",
    "    s = multispace_re.sub(\" \", s).strip()\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ca42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories to scrape\n",
    "TARGET_CATEGORIES = [\n",
    "    \"Produce\",\n",
    "    \"Meat & Seafood\",\n",
    "    \"Dairy & Eggs\",\n",
    "    \"Bakery\",\n",
    "    \"Pantry\",\n",
    "    \"Frozen Foods\",\n",
    "    \"Beverages\",\n",
    "    \"Snacks\",\n",
    "    \"Personal Care\",\n",
    "    \"Household\",\n",
    "    \"Pet Supplies\",\n",
    "    \"Deli\",\n",
    "    \"Condiments & Sauces\",\n",
    "    \"Canned Goods\",\n",
    "    \"Pasta & Grains\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "\n",
    "def normalise_category(cat):\n",
    "    if not cat:\n",
    "        return \"Other\"\n",
    "\n",
    "    cat = cat.strip().lower()\n",
    "\n",
    "    mapping = {\n",
    "        \"produce\": \"Produce\",\n",
    "        \"meat & seafood\": \"Meat & Seafood\",\n",
    "        \"dairy & eggs\": \"Dairy & Eggs\",\n",
    "        \"bakery\": \"Bakery\",\n",
    "        \"pantry\": \"Pantry\",\n",
    "        \"frozen foods\": \"Frozen Foods\",\n",
    "        \"beverages\": \"Beverages\",\n",
    "        \"snacks\": \"Snacks\",\n",
    "        \"personal care\": \"Personal Care\",\n",
    "        \"household\": \"Household\",\n",
    "        \"pet supplies\": \"Pet Supplies\",\n",
    "        \"deli\": \"Deli\",\n",
    "        \"condiments & sauces\": \"Condiments & Sauces\",\n",
    "        \"canned goods\": \"Canned Goods\",\n",
    "        \"pasta & grains\": \"Pasta & Grains\",\n",
    "        \"other\": \"Other\",\n",
    "    }\n",
    "\n",
    "    if cat in mapping:\n",
    "        return mapping[cat]\n",
    "    else:\n",
    "        return \"Other\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea92b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open food facts (off) -> manual category mapping -- used ChatGPT to help generate this list\n",
    "off_to_manual_category = {\n",
    "    \"produce\": [\n",
    "        \"en:fruits\", \"en:vegetables\", \"en:fruit\", \"en:vegetable\",\n",
    "        \"en:produce\", \"en:salads\", \"en:herbs\"\n",
    "    ],\n",
    "    \"dairy & eggs\": [\n",
    "        \"en:dairies\", \"en:dairy\", \"en:milk-and-yogurt\", \"en:cheeses\",\n",
    "        \"en:yogurts\", \"en:eggs\", \"en:butter\", \"en:cream\"\n",
    "    ],\n",
    "    \"meat & seafood\": [\n",
    "        \"en:meats\", \"en:meat\", \"en:poultry\",\n",
    "        \"en:sausages\", \"en:fish-and-seafood\"\n",
    "    ],\n",
    "    \"bakery\": [\n",
    "        \"en:breads\", \"en:bread\", \"en:bakery-products\",\n",
    "        \"en:cakes\", \"en:biscuits\", \"en:pastries\"\n",
    "    ],\n",
    "    \"snacks\": [\n",
    "        \"en:snacks\", \"en:salty-snacks\", \"en:crisps\",\n",
    "        \"en:chips\", \"en:snack-foods\", \"en:confectioneries\"\n",
    "    ],\n",
    "    \"beverages\": [\n",
    "        \"en:beverages\", \"en:drinks\", \"en:soft-drinks\",\n",
    "        \"en:juices\", \"en:teas\", \"en:coffees\"\n",
    "    ],\n",
    "    \"canned goods\": [\n",
    "        \"en:canned-foods\", \"en:canned-vegetables\",\n",
    "        \"en:canned-fruits\", \"en:canned-fish\"\n",
    "    ],\n",
    "    \"condiments & sauces\": [\n",
    "        \"en:condiments\", \"en:sauces\", \"en:ketchups\", \"en:mustards\",\n",
    "        \"en:mayonnaises\", \"en:salad-dressings\"\n",
    "    ],\n",
    "    \"pasta & grains\": [\n",
    "        \"en:pasta\", \"en:rices\", \"en:cereals\", \"en:flours\",\n",
    "        \"en:grains\"\n",
    "    ],\n",
    "    \"frozen foods\": [\n",
    "        \"en:frozen-foods\", \"en:frozen\", \"en:ice-creams\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "def map_off_to_category(off_tags):\n",
    "    off_tags = set(off_tags or [])\n",
    "    for manual_cat, off_cats in off_to_manual_category.items():\n",
    "        if any(tag in off_tags for tag in off_cats):\n",
    "            return manual_cat\n",
    "    return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deca0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape products from Open Food Facts\n",
    "def fetch_off_page(country: str, page: int, page_size: int = 1000):\n",
    "    url = \"https://uk.openfoodfacts.org/cgi/search.pl\"\n",
    "    params = {\n",
    "        \"search_simple\": 1,\n",
    "        \"action\": \"process\",\n",
    "        \"json\": 1,\n",
    "        \"page\": page,\n",
    "        \"page_size\": page_size,\n",
    "        \"fields\": (\n",
    "            \"product_name,product_name_en,\"\n",
    "            \"generic_name,generic_name_en,\"\n",
    "            \"categories_tags,brands,quantity\"\n",
    "        ),\n",
    "        \"country\": country,\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        return {}\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def build_off_dataset(country=\"united-kingdom\", pages=10, page_size=500, sleep_s=1.0) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    seen = set()\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        data = fetch_off_page(country=country, page=page, page_size=page_size)\n",
    "        products = data.get(\"products\", [])\n",
    "\n",
    "        for p in products:\n",
    "            name = (\n",
    "                p.get(\"product_name_en\")\n",
    "                or p.get(\"product_name\")\n",
    "                or p.get(\"generic_name_en\")\n",
    "                or p.get(\"generic_name\")\n",
    "                or \"\"\n",
    "            )\n",
    "            name_clean = clean_name(name)\n",
    "            if len(name_clean) < 3:\n",
    "                continue\n",
    "            if name_clean in seen:\n",
    "                continue\n",
    "            seen.add(name_clean)\n",
    "\n",
    "            manual_cat = map_off_to_category(p.get(\"categories_tags\", []))\n",
    "            cat = normalise_category(manual_cat)\n",
    "            rows.append({\"Item\": name_clean, \"Category\": cat})\n",
    "\n",
    "        print(\n",
    "            f\"[OFF] Page {page}/{pages}: +{len(products)} products, \"\n",
    "            f\"dataset size now {len(rows)}\"\n",
    "        )\n",
    "        time.sleep(sleep_s)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87309589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_titles_css(url, category, css_selector):\n",
    "    print(\"Fetching\", category, \"from\", url)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching page:\", e)\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Category\"])\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    rows = []\n",
    "    elements = soup.select(css_selector)\n",
    "\n",
    "    for el in elements:\n",
    "        text = el.get_text(strip=True)\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        name_clean = clean_name(text)\n",
    "        if len(name_clean) < 3:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"Item\": name_clean,\n",
    "            \"Category\": normalise_category(category)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.drop_duplicates(subset=[\"Item\", \"Category\"]).reset_index(drop=True)\n",
    "\n",
    "    print(\"Collected\", len(df), \"items for\", category)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06aae8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pets_at_home():\n",
    "    # build Pet Supplies dataset from Pets at Home\n",
    "    urls = [\n",
    "        \"https://www.petsathome.com/product/listing/dog/dog-food\",\n",
    "        \"https://www.petsathome.com/product/listing/cat/cat-food/dry-cat-food\",\n",
    "        \"https://www.petsathome.com/product/listing/fish/fish-food\",\n",
    "        \"https://www.petsathome.com/product/listing/bird-and-wildlife/wildbird-food\",\n",
    "        \"https://www.petsathome.com/product/listing/small-animal/rabbit/rabbit-food-and-feeding-hay\",\n",
    "        \"https://www.petsathome.com/product/listing/small-animal/hamster/hamster-food\",\n",
    "    ]\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    for url in urls:\n",
    "        # product titles are inside <h3 class=\"product-info_title__2XVM2\">\n",
    "        df_cat = scrape_titles_css(\n",
    "            url,\n",
    "            \"Pet Supplies\",\n",
    "            \"h3.product-info_title__2XVM2\"\n",
    "        )\n",
    "\n",
    "        if not df_cat.empty:\n",
    "            all_dfs.append(df_cat)\n",
    "\n",
    "    if len(all_dfs) == 0:\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Category\"])\n",
    "\n",
    "    result = pd.concat(all_dfs, ignore_index=True)\n",
    "    result = result.drop_duplicates(subset=[\"Item\", \"Category\"]).reset_index(drop=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_eataly_food():\n",
    "    # build food categories from Eataly (Pasta & Grains, Condiments & Sauces, Canned Goods)\n",
    "    url_map = {\n",
    "        \"Pasta & Grains\": \"https://www.eataly.com/us_en/nationwide-shipping/pasta\",\n",
    "        \"Condiments & Sauces\": \"https://www.eataly.com/us_en/nationwide-shipping/pantry/salt-and-spices\",\n",
    "        \"Canned Goods\": \"https://www.eataly.com/us_en/nationwide-shipping/pantry/canned-goods\",\n",
    "    }\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    for category_name, url in url_map.items():\n",
    "        # product titles are inside this div\n",
    "        df_cat = scrape_titles_css(\n",
    "            url,\n",
    "            category_name,\n",
    "            'div.product-card-name span'\n",
    "        )\n",
    "\n",
    "        if not df_cat.empty:\n",
    "            all_dfs.append(df_cat)\n",
    "\n",
    "    if len(all_dfs) == 0:\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Category\"])\n",
    "\n",
    "    result = pd.concat(all_dfs, ignore_index=True)\n",
    "    result = result.drop_duplicates(subset=[\"Item\", \"Category\"]).reset_index(drop=True)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "380844bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Pet Supplies from https://www.petsathome.com/product/listing/dog/dog-food\n",
      "Collected 40 items for Pet Supplies\n",
      "Fetching Pet Supplies from https://www.petsathome.com/product/listing/cat/cat-food/dry-cat-food\n",
      "Collected 36 items for Pet Supplies\n",
      "Fetching Pet Supplies from https://www.petsathome.com/product/listing/fish/fish-food\n",
      "Collected 38 items for Pet Supplies\n",
      "Fetching Pet Supplies from https://www.petsathome.com/product/listing/bird-and-wildlife/wildbird-food\n",
      "Collected 37 items for Pet Supplies\n",
      "Fetching Pet Supplies from https://www.petsathome.com/product/listing/small-animal/rabbit/rabbit-food-and-feeding-hay\n",
      "Collected 36 items for Pet Supplies\n",
      "Fetching Pet Supplies from https://www.petsathome.com/product/listing/small-animal/hamster/hamster-food\n",
      "Collected 12 items for Pet Supplies\n",
      "Fetching Pasta & Grains from https://www.eataly.com/us_en/nationwide-shipping/pasta\n",
      "Collected 0 items for Pasta & Grains\n",
      "Fetching Condiments & Sauces from https://www.eataly.com/us_en/nationwide-shipping/pantry/salt-and-spices\n",
      "Collected 0 items for Condiments & Sauces\n",
      "Fetching Canned Goods from https://www.eataly.com/us_en/nationwide-shipping/pantry/canned-goods\n",
      "Collected 0 items for Canned Goods\n",
      "[OFF] Page 1/10: +100 products, dataset size now 91\n",
      "[OFF] Page 2/10: +100 products, dataset size now 184\n",
      "[OFF] Page 3/10: +100 products, dataset size now 273\n",
      "[OFF] Page 4/10: +100 products, dataset size now 359\n",
      "[OFF] Page 5/10: +100 products, dataset size now 445\n",
      "[OFF] Page 6/10: +100 products, dataset size now 532\n",
      "[OFF] Page 7/10: +100 products, dataset size now 621\n",
      "[OFF] Page 8/10: +100 products, dataset size now 710\n",
      "[OFF] Page 9/10: +100 products, dataset size now 793\n",
      "[OFF] Page 10/10: +100 products, dataset size now 876\n"
     ]
    }
   ],
   "source": [
    "# build the datasets\n",
    "pets_df = build_pets_at_home()\n",
    "eataly_df = build_eataly_food()\n",
    "off_df = build_off_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7244cd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wainwright's sensitive adult dry dog food atla...</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wainwright's complete adult dry dog food salmo...</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wainwright's complete adult dry dog food turke...</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wainwright's dry adult dog food beef with supe...</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hill's science plan sensitive stomach &amp; skin m...</td>\n",
       "      <td>Pet Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>barista coconut</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>grissini breadsticks</td>\n",
       "      <td>Bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>unsalted roasted nuts</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>salted microwave popcorn</td>\n",
       "      <td>Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>chopped tomatoes 4pk</td>\n",
       "      <td>Produce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1074 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Item      Category\n",
       "0     wainwright's sensitive adult dry dog food atla...  Pet Supplies\n",
       "1     wainwright's complete adult dry dog food salmo...  Pet Supplies\n",
       "2     wainwright's complete adult dry dog food turke...  Pet Supplies\n",
       "3     wainwright's dry adult dog food beef with supe...  Pet Supplies\n",
       "4     hill's science plan sensitive stomach & skin m...  Pet Supplies\n",
       "...                                                 ...           ...\n",
       "1069                                    barista coconut     Beverages\n",
       "1070                               grissini breadsticks        Bakery\n",
       "1071                              unsalted roasted nuts         Other\n",
       "1072                           salted microwave popcorn        Snacks\n",
       "1073                               chopped tomatoes 4pk       Produce\n",
       "\n",
       "[1074 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine them into one df\n",
    "scraped_df = pd.concat([pets_df, eataly_df, off_df], ignore_index=True)\n",
    "\n",
    "# clean categories one last time\n",
    "scraped_df[\"Category\"] = scraped_df[\"Category\"].apply(normalise_category)\n",
    "\n",
    "# drop duplicates again, just in case\n",
    "scraped_df = scraped_df.drop_duplicates(subset=[\"Item\", \"Category\"]).reset_index(drop=True)\n",
    "\n",
    "scraped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d943684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "Other                  269\n",
      "Pet Supplies           212\n",
      "Snacks                 171\n",
      "Bakery                 166\n",
      "Dairy & Eggs           108\n",
      "Beverages               93\n",
      "Condiments & Sauces     89\n",
      "Produce                 62\n",
      "Meat & Seafood          43\n",
      "Frozen Foods            36\n",
      "Household               35\n",
      "Canned Goods            32\n",
      "Pasta & Grains          21\n",
      "Pantry                  18\n",
      "Personal Care           16\n",
      "Deli                    13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# build final dataset and save - combine scraped dataset with data.csv and extra_manual_items.csv\n",
    "\n",
    "# load existing CSV datasets\n",
    "data_df = pd.read_csv(\"data/data.csv\")\n",
    "manual_df = pd.read_csv(\"data/extra_manual_items.csv\")\n",
    "\n",
    "# clean manual + csv data\n",
    "data_df[\"Item\"] = data_df[\"Item\"].apply(clean_name)\n",
    "data_df[\"Category\"] = data_df[\"Category\"].apply(normalise_category)\n",
    "\n",
    "manual_df[\"Item\"] = manual_df[\"Item\"].apply(clean_name)\n",
    "manual_df[\"Category\"] = manual_df[\"Category\"].apply(normalise_category)\n",
    "\n",
    "# combine scraped data with CSV data\n",
    "df = pd.concat([scraped_df, data_df, manual_df], ignore_index=True)\n",
    "\n",
    "# clean categories one last time\n",
    "df[\"Category\"] = df[\"Category\"].apply(normalise_category)\n",
    "\n",
    "# remove duplicates\n",
    "df = df.drop_duplicates(subset=[\"Item\", \"Category\"]).reset_index(drop=True)\n",
    "\n",
    "# save final dataset\n",
    "df.to_csv(\"data/final_grocery_dataset.csv\", index=False)\n",
    "\n",
    "print(df[\"Category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "975f8021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Other                  269\n",
       "Pet Supplies           212\n",
       "Snacks                 171\n",
       "Bakery                 166\n",
       "Dairy & Eggs           108\n",
       "Beverages               93\n",
       "Condiments & Sauces     89\n",
       "Produce                 62\n",
       "Meat & Seafood          43\n",
       "Frozen Foods            36\n",
       "Household               35\n",
       "Canned Goods            32\n",
       "Pasta & Grains          21\n",
       "Pantry                  18\n",
       "Personal Care           16\n",
       "Deli                    13\n",
       "Name: Item, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"Category\"].value_counts()\n",
    "df.groupby(\"Category\")[\"Item\"].nunique().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding-five",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
